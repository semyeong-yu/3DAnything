{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a591a46e",
   "metadata": {},
   "source": [
    "- 다중 control signal을 사용하는 model을 만들기 위한 곳\n",
    "- 현재 분석으로는 256 by 256으로 finetune 되었다는 점이 크게 작용한다.\n",
    "- 약간의 variant라고 한다면, \"model.diffusion_model.input_blocks.0.0.weight\" 이 부분이 input dimension이 8이 되었기 떄문에 avearage를 취해야 겠다.\n",
    "- 학습 scale이 lab scale은 아니고 중소기업 정도는 되기 때문에, 역시 이를 control signal형태로 사용하는 것은 적절한 관측이 될 것으로 보인다.\n",
    "- 그래도 30K scale의 finetune을 거치기 때문에, spatial resolution에 의한 문제는 크게 발생하지 않을 것으로 보인다.\n",
    "- [ ] control signal composition에 대한 실험만 거치면 될 것으로 보인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82628974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7e789bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "repo_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(repo_path)\n",
    "\n",
    "repo_path_2 = \"/workspace/code/3DAnything/zero123\"\n",
    "sys.path.append(repo_path_2)\n",
    "\n",
    "from zero123.ldm.util import instantiate_from_config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8f9f8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state_dict_to_jsonl(state_dict, output_file_path):\n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "        for key, value in state_dict.items():\n",
    "            json_line = {\"key\": key, \"shape\": value.shape}\n",
    "            json.dump(json_line, f, ensure_ascii=False)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cfdf626",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cfg_path = \"/workspace/code/3DAnything/zero123/configs/canny-edge_variant.yaml\"\n",
    "test_cfg = OmegaConf.load(test_cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "46066032",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_orig_cfg_path = \"/workspace/code/3DAnything/zero123/configs/sd-objaverse-finetune-c_concat-256.yaml\"\n",
    "test_orig_cfg = OmegaConf.load(test_orig_cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ControlLDM: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/clip/clip.py:57: UserWarning: /root/.cache/clip/ViT-L-14.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(f\"{download_target} exists, but the SHA256 checksum does not match; re-downloading the file\")\n",
      "100%|████████████████████████████████████████| 890M/890M [20:48<00:00, 747kiB/s]\n"
     ]
    }
   ],
   "source": [
    "model = instantiate_from_config(test_cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a95b5df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.53 M params.\n",
      "Keeping EMAs of 688.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    }
   ],
   "source": [
    "model_orig = instantiate_from_config(test_orig_cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bff5faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tensor = torch.randn(1, 3, 256, 256)\n",
    "test_tensor = test_tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eb7d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.first_stage_model\n",
    "vae = model.first_stage_model.to(\"cuda\")\n",
    "\n",
    "\n",
    "\n",
    "# 여기는 그대로 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ad5e751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_2 = model_orig.first_stage_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a18557a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vae.encode(test_tensor)\n",
    "result_2 = vae_2.encode(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8b2db923",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_sampled = result.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4e644865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 32, 32])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "929a0943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 32, 32])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result.mean.shape\n",
    "result_2.mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ddc5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ControlledUnetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1-2): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10-11): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GEGLU(\n",
       "                (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0-1): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3-4): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10-11): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.diffusion_model\n",
    "# 여기를 T2I 모델로 바꿔야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ebda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): TimestepEmbedSequential(\n",
       "    (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (1-2): 2 x TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "            (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "            (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GEGLU(\n",
       "                (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (3): TimestepEmbedSequential(\n",
       "    (0): Downsample(\n",
       "      (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (4): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "            (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "            (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GEGLU(\n",
       "                (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (5): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "            (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "            (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GEGLU(\n",
       "                (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (6): TimestepEmbedSequential(\n",
       "    (0): Downsample(\n",
       "      (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (7): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GEGLU(\n",
       "                (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (8): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GEGLU(\n",
       "                (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (9): TimestepEmbedSequential(\n",
       "    (0): Downsample(\n",
       "      (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (10-11): 2 x TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.diffusion_model.input_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663db600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenCLIPImageEmbedder(\n",
       "  (model): CLIP(\n",
       "    (visual): VisionTransformer(\n",
       "      (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "      (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): Sequential(\n",
       "          (0): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (12): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (15): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (16): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (17): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (18): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (19): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (20): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (21): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (22): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (23): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (token_embedding): Embedding(49408, 768)\n",
       "    (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cond_stage_model\n",
    "# 이 부분의 clip을 치환하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "92ac5200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-3): 4 x TimestepEmbedSequential(\n",
       "    (0): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (4-6): 3 x TimestepEmbedSequential(\n",
       "    (0): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (7-11): 5 x TimestepEmbedSequential(\n",
       "    (0): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.control_model.zero_convs\n",
    "# 여기는 code implementation을 약간 바꿔야 한다. 이종 control을 둘 다 넣기 위해서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0568bc26",
   "metadata": {},
   "source": [
    "# test_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f2427e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoencoderKL(\n",
       "  (encoder): Encoder(\n",
       "    (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (down): ModuleList(\n",
       "      (0): Module(\n",
       "        (block): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "        (downsample): Downsample(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (1): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "        (downsample): Downsample(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (2): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "        (downsample): Downsample(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (3): Module(\n",
       "        (block): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "      )\n",
       "    )\n",
       "    (mid): Module(\n",
       "      (block_1): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (attn_1): AttnBlock(\n",
       "        (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (block_2): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (norm_out): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "    (conv_out): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (conv_in): Conv2d(4, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (mid): Module(\n",
       "      (block_1): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (attn_1): AttnBlock(\n",
       "        (norm): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (block_2): ResnetBlock(\n",
       "        (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (up): ModuleList(\n",
       "      (0): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "      )\n",
       "      (1): Module(\n",
       "        (block): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "        (upsample): Upsample(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (2-3): 2 x Module(\n",
       "        (block): ModuleList(\n",
       "          (0-2): 3 x ResnetBlock(\n",
       "            (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (norm2): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (attn): ModuleList()\n",
       "        (upsample): Upsample(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm_out): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
       "    (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (loss): Identity()\n",
       "  (quant_conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (post_quant_conv): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_orig.first_stage_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19bfe623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=320, out_features=1280, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(8, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1-2): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): Downsample(\n",
       "        (op): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10-11): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GEGLU(\n",
       "                (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0-1): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3-4): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 2560, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1920, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 1280, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=640, out_features=640, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 960, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10-11): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GEGLU(\n",
       "                  (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=320, out_features=320, bias=True)\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 320, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_orig.model.diffusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8226c3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 8, 3, 3])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_orig.model.diffusion_model.input_blocks[0][0].weight.shape\n",
    "# 여기 convolution layer만 control하면 될 듯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868e99be",
   "metadata": {},
   "source": [
    "# SD weight 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_path = \"/workspace/weight/diffuse/stable-diffusion-v-1-4-original/sd-v1-4.ckpt\"\n",
    "sd_cfg_path = \"/workspace/code/3DAnything/zero123/configs/sd-v1-inference.yaml\"\n",
    "sd_cfg = OmegaConf.load(sd_cfg_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1bbbd73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'base_learning_rate': 0.0001, 'target': 'ldm.models.diffusion.ddpm.LatentDiffusion', 'params': {'linear_start': 0.00085, 'linear_end': 0.012, 'num_timesteps_cond': 1, 'log_every_t': 200, 'timesteps': 1000, 'first_stage_key': 'jpg', 'cond_stage_key': 'txt', 'image_size': 64, 'channels': 4, 'cond_stage_trainable': False, 'conditioning_key': 'crossattn', 'monitor': 'val/loss_simple_ema', 'scale_factor': 0.18215, 'use_ema': False, 'scheduler_config': {'target': 'ldm.lr_scheduler.LambdaLinearScheduler', 'params': {'warm_up_steps': [10000], 'cycle_lengths': [10000000000000], 'f_start': [1e-06], 'f_max': [1.0], 'f_min': [1.0]}}, 'unet_config': {'target': 'ldm.modules.diffusionmodules.openaimodel.UNetModel', 'params': {'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_heads': 8, 'use_spatial_transformer': True, 'transformer_depth': 1, 'context_dim': 768, 'use_checkpoint': True, 'legacy': False}}, 'first_stage_config': {'target': 'ldm.models.autoencoder.AutoencoderKL', 'params': {'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}}, 'cond_stage_config': {'target': 'ldm.modules.encoders.modules.FrozenCLIPEmbedder'}}}}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3b0bbe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f43ddbbab84ad2b74e4d7c2bfc0c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/905 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4279db9d9864f45a41a8b00bf545c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0089015ae244bd2a4864258e9e51181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4e4a01be0c4f7ea72cd7a181bba9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fab7e279dc04159aa16ffa3904e08e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580a8d8cf3b34d40a714739b3072a4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36b57619f52416c95855e42feab6677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sd_model = instantiate_from_config(sd_cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2e1aa9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weight = torch.load(sd_path, map_location=\"cpu\")[\"state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ab8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['betas', 'alphas_cumprod', 'alphas_cumprod_prev', 'sqrt_alphas_cumprod', 'sqrt_one_minus_alphas_cumprod', 'log_one_minus_alphas_cumprod', 'sqrt_recip_alphas_cumprod', 'sqrt_recipm1_alphas_cumprod', 'posterior_variance', 'posterior_log_variance_clipped', 'posterior_mean_coef1', 'posterior_mean_coef2', 'model.diffusion_model.time_embed.0.weight', 'model.diffusion_model.time_embed.0.bias', 'model.diffusion_model.time_embed.2.weight', 'model.diffusion_model.time_embed.2.bias', 'model.diffusion_model.input_blocks.0.0.weight', 'model.diffusion_model.input_blocks.0.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.1.1.norm.weight', 'model.diffusion_model.input_blocks.1.1.norm.bias', 'model.diffusion_model.input_blocks.1.1.proj_in.weight', 'model.diffusion_model.input_blocks.1.1.proj_in.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.1.1.proj_out.weight', 'model.diffusion_model.input_blocks.1.1.proj_out.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.2.1.norm.weight', 'model.diffusion_model.input_blocks.2.1.norm.bias', 'model.diffusion_model.input_blocks.2.1.proj_in.weight', 'model.diffusion_model.input_blocks.2.1.proj_in.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.2.1.proj_out.weight', 'model.diffusion_model.input_blocks.2.1.proj_out.bias', 'model.diffusion_model.input_blocks.3.0.op.weight', 'model.diffusion_model.input_blocks.3.0.op.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.4.0.skip_connection.weight', 'model.diffusion_model.input_blocks.4.0.skip_connection.bias', 'model.diffusion_model.input_blocks.4.1.norm.weight', 'model.diffusion_model.input_blocks.4.1.norm.bias', 'model.diffusion_model.input_blocks.4.1.proj_in.weight', 'model.diffusion_model.input_blocks.4.1.proj_in.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.4.1.proj_out.weight', 'model.diffusion_model.input_blocks.4.1.proj_out.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.5.1.norm.weight', 'model.diffusion_model.input_blocks.5.1.norm.bias', 'model.diffusion_model.input_blocks.5.1.proj_in.weight', 'model.diffusion_model.input_blocks.5.1.proj_in.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.5.1.proj_out.weight', 'model.diffusion_model.input_blocks.5.1.proj_out.bias', 'model.diffusion_model.input_blocks.6.0.op.weight', 'model.diffusion_model.input_blocks.6.0.op.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.7.0.skip_connection.weight', 'model.diffusion_model.input_blocks.7.0.skip_connection.bias', 'model.diffusion_model.input_blocks.7.1.norm.weight', 'model.diffusion_model.input_blocks.7.1.norm.bias', 'model.diffusion_model.input_blocks.7.1.proj_in.weight', 'model.diffusion_model.input_blocks.7.1.proj_in.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.7.1.proj_out.weight', 'model.diffusion_model.input_blocks.7.1.proj_out.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.8.1.norm.weight', 'model.diffusion_model.input_blocks.8.1.norm.bias', 'model.diffusion_model.input_blocks.8.1.proj_in.weight', 'model.diffusion_model.input_blocks.8.1.proj_in.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.8.1.proj_out.weight', 'model.diffusion_model.input_blocks.8.1.proj_out.bias', 'model.diffusion_model.input_blocks.9.0.op.weight', 'model.diffusion_model.input_blocks.9.0.op.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.middle_block.0.in_layers.0.weight', 'model.diffusion_model.middle_block.0.in_layers.0.bias', 'model.diffusion_model.middle_block.0.in_layers.2.weight', 'model.diffusion_model.middle_block.0.in_layers.2.bias', 'model.diffusion_model.middle_block.0.emb_layers.1.weight', 'model.diffusion_model.middle_block.0.emb_layers.1.bias', 'model.diffusion_model.middle_block.0.out_layers.0.weight', 'model.diffusion_model.middle_block.0.out_layers.0.bias', 'model.diffusion_model.middle_block.0.out_layers.3.weight', 'model.diffusion_model.middle_block.0.out_layers.3.bias', 'model.diffusion_model.middle_block.1.norm.weight', 'model.diffusion_model.middle_block.1.norm.bias', 'model.diffusion_model.middle_block.1.proj_in.weight', 'model.diffusion_model.middle_block.1.proj_in.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.middle_block.1.proj_out.weight', 'model.diffusion_model.middle_block.1.proj_out.bias', 'model.diffusion_model.middle_block.2.in_layers.0.weight', 'model.diffusion_model.middle_block.2.in_layers.0.bias', 'model.diffusion_model.middle_block.2.in_layers.2.weight', 'model.diffusion_model.middle_block.2.in_layers.2.bias', 'model.diffusion_model.middle_block.2.emb_layers.1.weight', 'model.diffusion_model.middle_block.2.emb_layers.1.bias', 'model.diffusion_model.middle_block.2.out_layers.0.weight', 'model.diffusion_model.middle_block.2.out_layers.0.bias', 'model.diffusion_model.middle_block.2.out_layers.3.weight', 'model.diffusion_model.middle_block.2.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.skip_connection.weight', 'model.diffusion_model.output_blocks.0.0.skip_connection.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.1.0.skip_connection.weight', 'model.diffusion_model.output_blocks.1.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.2.0.skip_connection.weight', 'model.diffusion_model.output_blocks.2.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.1.conv.weight', 'model.diffusion_model.output_blocks.2.1.conv.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.3.0.skip_connection.weight', 'model.diffusion_model.output_blocks.3.0.skip_connection.bias', 'model.diffusion_model.output_blocks.3.1.norm.weight', 'model.diffusion_model.output_blocks.3.1.norm.bias', 'model.diffusion_model.output_blocks.3.1.proj_in.weight', 'model.diffusion_model.output_blocks.3.1.proj_in.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.3.1.proj_out.weight', 'model.diffusion_model.output_blocks.3.1.proj_out.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.4.0.skip_connection.weight', 'model.diffusion_model.output_blocks.4.0.skip_connection.bias', 'model.diffusion_model.output_blocks.4.1.norm.weight', 'model.diffusion_model.output_blocks.4.1.norm.bias', 'model.diffusion_model.output_blocks.4.1.proj_in.weight', 'model.diffusion_model.output_blocks.4.1.proj_in.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.4.1.proj_out.weight', 'model.diffusion_model.output_blocks.4.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.5.0.skip_connection.weight', 'model.diffusion_model.output_blocks.5.0.skip_connection.bias', 'model.diffusion_model.output_blocks.5.1.norm.weight', 'model.diffusion_model.output_blocks.5.1.norm.bias', 'model.diffusion_model.output_blocks.5.1.proj_in.weight', 'model.diffusion_model.output_blocks.5.1.proj_in.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.5.1.proj_out.weight', 'model.diffusion_model.output_blocks.5.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.2.conv.weight', 'model.diffusion_model.output_blocks.5.2.conv.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.6.0.skip_connection.weight', 'model.diffusion_model.output_blocks.6.0.skip_connection.bias', 'model.diffusion_model.output_blocks.6.1.norm.weight', 'model.diffusion_model.output_blocks.6.1.norm.bias', 'model.diffusion_model.output_blocks.6.1.proj_in.weight', 'model.diffusion_model.output_blocks.6.1.proj_in.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.6.1.proj_out.weight', 'model.diffusion_model.output_blocks.6.1.proj_out.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.7.0.skip_connection.weight', 'model.diffusion_model.output_blocks.7.0.skip_connection.bias', 'model.diffusion_model.output_blocks.7.1.norm.weight', 'model.diffusion_model.output_blocks.7.1.norm.bias', 'model.diffusion_model.output_blocks.7.1.proj_in.weight', 'model.diffusion_model.output_blocks.7.1.proj_in.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.7.1.proj_out.weight', 'model.diffusion_model.output_blocks.7.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.8.0.skip_connection.weight', 'model.diffusion_model.output_blocks.8.0.skip_connection.bias', 'model.diffusion_model.output_blocks.8.1.norm.weight', 'model.diffusion_model.output_blocks.8.1.norm.bias', 'model.diffusion_model.output_blocks.8.1.proj_in.weight', 'model.diffusion_model.output_blocks.8.1.proj_in.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.8.1.proj_out.weight', 'model.diffusion_model.output_blocks.8.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.2.conv.weight', 'model.diffusion_model.output_blocks.8.2.conv.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.9.0.skip_connection.weight', 'model.diffusion_model.output_blocks.9.0.skip_connection.bias', 'model.diffusion_model.output_blocks.9.1.norm.weight', 'model.diffusion_model.output_blocks.9.1.norm.bias', 'model.diffusion_model.output_blocks.9.1.proj_in.weight', 'model.diffusion_model.output_blocks.9.1.proj_in.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.9.1.proj_out.weight', 'model.diffusion_model.output_blocks.9.1.proj_out.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.10.0.skip_connection.weight', 'model.diffusion_model.output_blocks.10.0.skip_connection.bias', 'model.diffusion_model.output_blocks.10.1.norm.weight', 'model.diffusion_model.output_blocks.10.1.norm.bias', 'model.diffusion_model.output_blocks.10.1.proj_in.weight', 'model.diffusion_model.output_blocks.10.1.proj_in.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.10.1.proj_out.weight', 'model.diffusion_model.output_blocks.10.1.proj_out.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.11.0.skip_connection.weight', 'model.diffusion_model.output_blocks.11.0.skip_connection.bias', 'model.diffusion_model.output_blocks.11.1.norm.weight', 'model.diffusion_model.output_blocks.11.1.norm.bias', 'model.diffusion_model.output_blocks.11.1.proj_in.weight', 'model.diffusion_model.output_blocks.11.1.proj_in.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.11.1.proj_out.weight', 'model.diffusion_model.output_blocks.11.1.proj_out.bias', 'model.diffusion_model.out.0.weight', 'model.diffusion_model.out.0.bias', 'model.diffusion_model.out.2.weight', 'model.diffusion_model.out.2.bias', 'model_ema.decay', 'model_ema.num_updates', 'first_stage_model.encoder.conv_in.weight', 'first_stage_model.encoder.conv_in.bias', 'first_stage_model.encoder.down.0.block.0.norm1.weight', 'first_stage_model.encoder.down.0.block.0.norm1.bias', 'first_stage_model.encoder.down.0.block.0.conv1.weight', 'first_stage_model.encoder.down.0.block.0.conv1.bias', 'first_stage_model.encoder.down.0.block.0.norm2.weight', 'first_stage_model.encoder.down.0.block.0.norm2.bias', 'first_stage_model.encoder.down.0.block.0.conv2.weight', 'first_stage_model.encoder.down.0.block.0.conv2.bias', 'first_stage_model.encoder.down.0.block.1.norm1.weight', 'first_stage_model.encoder.down.0.block.1.norm1.bias', 'first_stage_model.encoder.down.0.block.1.conv1.weight', 'first_stage_model.encoder.down.0.block.1.conv1.bias', 'first_stage_model.encoder.down.0.block.1.norm2.weight', 'first_stage_model.encoder.down.0.block.1.norm2.bias', 'first_stage_model.encoder.down.0.block.1.conv2.weight', 'first_stage_model.encoder.down.0.block.1.conv2.bias', 'first_stage_model.encoder.down.0.downsample.conv.weight', 'first_stage_model.encoder.down.0.downsample.conv.bias', 'first_stage_model.encoder.down.1.block.0.norm1.weight', 'first_stage_model.encoder.down.1.block.0.norm1.bias', 'first_stage_model.encoder.down.1.block.0.conv1.weight', 'first_stage_model.encoder.down.1.block.0.conv1.bias', 'first_stage_model.encoder.down.1.block.0.norm2.weight', 'first_stage_model.encoder.down.1.block.0.norm2.bias', 'first_stage_model.encoder.down.1.block.0.conv2.weight', 'first_stage_model.encoder.down.1.block.0.conv2.bias', 'first_stage_model.encoder.down.1.block.0.nin_shortcut.weight', 'first_stage_model.encoder.down.1.block.0.nin_shortcut.bias', 'first_stage_model.encoder.down.1.block.1.norm1.weight', 'first_stage_model.encoder.down.1.block.1.norm1.bias', 'first_stage_model.encoder.down.1.block.1.conv1.weight', 'first_stage_model.encoder.down.1.block.1.conv1.bias', 'first_stage_model.encoder.down.1.block.1.norm2.weight', 'first_stage_model.encoder.down.1.block.1.norm2.bias', 'first_stage_model.encoder.down.1.block.1.conv2.weight', 'first_stage_model.encoder.down.1.block.1.conv2.bias', 'first_stage_model.encoder.down.1.downsample.conv.weight', 'first_stage_model.encoder.down.1.downsample.conv.bias', 'first_stage_model.encoder.down.2.block.0.norm1.weight', 'first_stage_model.encoder.down.2.block.0.norm1.bias', 'first_stage_model.encoder.down.2.block.0.conv1.weight', 'first_stage_model.encoder.down.2.block.0.conv1.bias', 'first_stage_model.encoder.down.2.block.0.norm2.weight', 'first_stage_model.encoder.down.2.block.0.norm2.bias', 'first_stage_model.encoder.down.2.block.0.conv2.weight', 'first_stage_model.encoder.down.2.block.0.conv2.bias', 'first_stage_model.encoder.down.2.block.0.nin_shortcut.weight', 'first_stage_model.encoder.down.2.block.0.nin_shortcut.bias', 'first_stage_model.encoder.down.2.block.1.norm1.weight', 'first_stage_model.encoder.down.2.block.1.norm1.bias', 'first_stage_model.encoder.down.2.block.1.conv1.weight', 'first_stage_model.encoder.down.2.block.1.conv1.bias', 'first_stage_model.encoder.down.2.block.1.norm2.weight', 'first_stage_model.encoder.down.2.block.1.norm2.bias', 'first_stage_model.encoder.down.2.block.1.conv2.weight', 'first_stage_model.encoder.down.2.block.1.conv2.bias', 'first_stage_model.encoder.down.2.downsample.conv.weight', 'first_stage_model.encoder.down.2.downsample.conv.bias', 'first_stage_model.encoder.down.3.block.0.norm1.weight', 'first_stage_model.encoder.down.3.block.0.norm1.bias', 'first_stage_model.encoder.down.3.block.0.conv1.weight', 'first_stage_model.encoder.down.3.block.0.conv1.bias', 'first_stage_model.encoder.down.3.block.0.norm2.weight', 'first_stage_model.encoder.down.3.block.0.norm2.bias', 'first_stage_model.encoder.down.3.block.0.conv2.weight', 'first_stage_model.encoder.down.3.block.0.conv2.bias', 'first_stage_model.encoder.down.3.block.1.norm1.weight', 'first_stage_model.encoder.down.3.block.1.norm1.bias', 'first_stage_model.encoder.down.3.block.1.conv1.weight', 'first_stage_model.encoder.down.3.block.1.conv1.bias', 'first_stage_model.encoder.down.3.block.1.norm2.weight', 'first_stage_model.encoder.down.3.block.1.norm2.bias', 'first_stage_model.encoder.down.3.block.1.conv2.weight', 'first_stage_model.encoder.down.3.block.1.conv2.bias', 'first_stage_model.encoder.mid.block_1.norm1.weight', 'first_stage_model.encoder.mid.block_1.norm1.bias', 'first_stage_model.encoder.mid.block_1.conv1.weight', 'first_stage_model.encoder.mid.block_1.conv1.bias', 'first_stage_model.encoder.mid.block_1.norm2.weight', 'first_stage_model.encoder.mid.block_1.norm2.bias', 'first_stage_model.encoder.mid.block_1.conv2.weight', 'first_stage_model.encoder.mid.block_1.conv2.bias', 'first_stage_model.encoder.mid.attn_1.norm.weight', 'first_stage_model.encoder.mid.attn_1.norm.bias', 'first_stage_model.encoder.mid.attn_1.q.weight', 'first_stage_model.encoder.mid.attn_1.q.bias', 'first_stage_model.encoder.mid.attn_1.k.weight', 'first_stage_model.encoder.mid.attn_1.k.bias', 'first_stage_model.encoder.mid.attn_1.v.weight', 'first_stage_model.encoder.mid.attn_1.v.bias', 'first_stage_model.encoder.mid.attn_1.proj_out.weight', 'first_stage_model.encoder.mid.attn_1.proj_out.bias', 'first_stage_model.encoder.mid.block_2.norm1.weight', 'first_stage_model.encoder.mid.block_2.norm1.bias', 'first_stage_model.encoder.mid.block_2.conv1.weight', 'first_stage_model.encoder.mid.block_2.conv1.bias', 'first_stage_model.encoder.mid.block_2.norm2.weight', 'first_stage_model.encoder.mid.block_2.norm2.bias', 'first_stage_model.encoder.mid.block_2.conv2.weight', 'first_stage_model.encoder.mid.block_2.conv2.bias', 'first_stage_model.encoder.norm_out.weight', 'first_stage_model.encoder.norm_out.bias', 'first_stage_model.encoder.conv_out.weight', 'first_stage_model.encoder.conv_out.bias', 'first_stage_model.decoder.conv_in.weight', 'first_stage_model.decoder.conv_in.bias', 'first_stage_model.decoder.mid.block_1.norm1.weight', 'first_stage_model.decoder.mid.block_1.norm1.bias', 'first_stage_model.decoder.mid.block_1.conv1.weight', 'first_stage_model.decoder.mid.block_1.conv1.bias', 'first_stage_model.decoder.mid.block_1.norm2.weight', 'first_stage_model.decoder.mid.block_1.norm2.bias', 'first_stage_model.decoder.mid.block_1.conv2.weight', 'first_stage_model.decoder.mid.block_1.conv2.bias', 'first_stage_model.decoder.mid.attn_1.norm.weight', 'first_stage_model.decoder.mid.attn_1.norm.bias', 'first_stage_model.decoder.mid.attn_1.q.weight', 'first_stage_model.decoder.mid.attn_1.q.bias', 'first_stage_model.decoder.mid.attn_1.k.weight', 'first_stage_model.decoder.mid.attn_1.k.bias', 'first_stage_model.decoder.mid.attn_1.v.weight', 'first_stage_model.decoder.mid.attn_1.v.bias', 'first_stage_model.decoder.mid.attn_1.proj_out.weight', 'first_stage_model.decoder.mid.attn_1.proj_out.bias', 'first_stage_model.decoder.mid.block_2.norm1.weight', 'first_stage_model.decoder.mid.block_2.norm1.bias', 'first_stage_model.decoder.mid.block_2.conv1.weight', 'first_stage_model.decoder.mid.block_2.conv1.bias', 'first_stage_model.decoder.mid.block_2.norm2.weight', 'first_stage_model.decoder.mid.block_2.norm2.bias', 'first_stage_model.decoder.mid.block_2.conv2.weight', 'first_stage_model.decoder.mid.block_2.conv2.bias', 'first_stage_model.decoder.up.0.block.0.norm1.weight', 'first_stage_model.decoder.up.0.block.0.norm1.bias', 'first_stage_model.decoder.up.0.block.0.conv1.weight', 'first_stage_model.decoder.up.0.block.0.conv1.bias', 'first_stage_model.decoder.up.0.block.0.norm2.weight', 'first_stage_model.decoder.up.0.block.0.norm2.bias', 'first_stage_model.decoder.up.0.block.0.conv2.weight', 'first_stage_model.decoder.up.0.block.0.conv2.bias', 'first_stage_model.decoder.up.0.block.0.nin_shortcut.weight', 'first_stage_model.decoder.up.0.block.0.nin_shortcut.bias', 'first_stage_model.decoder.up.0.block.1.norm1.weight', 'first_stage_model.decoder.up.0.block.1.norm1.bias', 'first_stage_model.decoder.up.0.block.1.conv1.weight', 'first_stage_model.decoder.up.0.block.1.conv1.bias', 'first_stage_model.decoder.up.0.block.1.norm2.weight', 'first_stage_model.decoder.up.0.block.1.norm2.bias', 'first_stage_model.decoder.up.0.block.1.conv2.weight', 'first_stage_model.decoder.up.0.block.1.conv2.bias', 'first_stage_model.decoder.up.0.block.2.norm1.weight', 'first_stage_model.decoder.up.0.block.2.norm1.bias', 'first_stage_model.decoder.up.0.block.2.conv1.weight', 'first_stage_model.decoder.up.0.block.2.conv1.bias', 'first_stage_model.decoder.up.0.block.2.norm2.weight', 'first_stage_model.decoder.up.0.block.2.norm2.bias', 'first_stage_model.decoder.up.0.block.2.conv2.weight', 'first_stage_model.decoder.up.0.block.2.conv2.bias', 'first_stage_model.decoder.up.1.block.0.norm1.weight', 'first_stage_model.decoder.up.1.block.0.norm1.bias', 'first_stage_model.decoder.up.1.block.0.conv1.weight', 'first_stage_model.decoder.up.1.block.0.conv1.bias', 'first_stage_model.decoder.up.1.block.0.norm2.weight', 'first_stage_model.decoder.up.1.block.0.norm2.bias', 'first_stage_model.decoder.up.1.block.0.conv2.weight', 'first_stage_model.decoder.up.1.block.0.conv2.bias', 'first_stage_model.decoder.up.1.block.0.nin_shortcut.weight', 'first_stage_model.decoder.up.1.block.0.nin_shortcut.bias', 'first_stage_model.decoder.up.1.block.1.norm1.weight', 'first_stage_model.decoder.up.1.block.1.norm1.bias', 'first_stage_model.decoder.up.1.block.1.conv1.weight', 'first_stage_model.decoder.up.1.block.1.conv1.bias', 'first_stage_model.decoder.up.1.block.1.norm2.weight', 'first_stage_model.decoder.up.1.block.1.norm2.bias', 'first_stage_model.decoder.up.1.block.1.conv2.weight', 'first_stage_model.decoder.up.1.block.1.conv2.bias', 'first_stage_model.decoder.up.1.block.2.norm1.weight', 'first_stage_model.decoder.up.1.block.2.norm1.bias', 'first_stage_model.decoder.up.1.block.2.conv1.weight', 'first_stage_model.decoder.up.1.block.2.conv1.bias', 'first_stage_model.decoder.up.1.block.2.norm2.weight', 'first_stage_model.decoder.up.1.block.2.norm2.bias', 'first_stage_model.decoder.up.1.block.2.conv2.weight', 'first_stage_model.decoder.up.1.block.2.conv2.bias', 'first_stage_model.decoder.up.1.upsample.conv.weight', 'first_stage_model.decoder.up.1.upsample.conv.bias', 'first_stage_model.decoder.up.2.block.0.norm1.weight', 'first_stage_model.decoder.up.2.block.0.norm1.bias', 'first_stage_model.decoder.up.2.block.0.conv1.weight', 'first_stage_model.decoder.up.2.block.0.conv1.bias', 'first_stage_model.decoder.up.2.block.0.norm2.weight', 'first_stage_model.decoder.up.2.block.0.norm2.bias', 'first_stage_model.decoder.up.2.block.0.conv2.weight', 'first_stage_model.decoder.up.2.block.0.conv2.bias', 'first_stage_model.decoder.up.2.block.1.norm1.weight', 'first_stage_model.decoder.up.2.block.1.norm1.bias', 'first_stage_model.decoder.up.2.block.1.conv1.weight', 'first_stage_model.decoder.up.2.block.1.conv1.bias', 'first_stage_model.decoder.up.2.block.1.norm2.weight', 'first_stage_model.decoder.up.2.block.1.norm2.bias', 'first_stage_model.decoder.up.2.block.1.conv2.weight', 'first_stage_model.decoder.up.2.block.1.conv2.bias', 'first_stage_model.decoder.up.2.block.2.norm1.weight', 'first_stage_model.decoder.up.2.block.2.norm1.bias', 'first_stage_model.decoder.up.2.block.2.conv1.weight', 'first_stage_model.decoder.up.2.block.2.conv1.bias', 'first_stage_model.decoder.up.2.block.2.norm2.weight', 'first_stage_model.decoder.up.2.block.2.norm2.bias', 'first_stage_model.decoder.up.2.block.2.conv2.weight', 'first_stage_model.decoder.up.2.block.2.conv2.bias', 'first_stage_model.decoder.up.2.upsample.conv.weight', 'first_stage_model.decoder.up.2.upsample.conv.bias', 'first_stage_model.decoder.up.3.block.0.norm1.weight', 'first_stage_model.decoder.up.3.block.0.norm1.bias', 'first_stage_model.decoder.up.3.block.0.conv1.weight', 'first_stage_model.decoder.up.3.block.0.conv1.bias', 'first_stage_model.decoder.up.3.block.0.norm2.weight', 'first_stage_model.decoder.up.3.block.0.norm2.bias', 'first_stage_model.decoder.up.3.block.0.conv2.weight', 'first_stage_model.decoder.up.3.block.0.conv2.bias', 'first_stage_model.decoder.up.3.block.1.norm1.weight', 'first_stage_model.decoder.up.3.block.1.norm1.bias', 'first_stage_model.decoder.up.3.block.1.conv1.weight', 'first_stage_model.decoder.up.3.block.1.conv1.bias', 'first_stage_model.decoder.up.3.block.1.norm2.weight', 'first_stage_model.decoder.up.3.block.1.norm2.bias', 'first_stage_model.decoder.up.3.block.1.conv2.weight', 'first_stage_model.decoder.up.3.block.1.conv2.bias', 'first_stage_model.decoder.up.3.block.2.norm1.weight', 'first_stage_model.decoder.up.3.block.2.norm1.bias', 'first_stage_model.decoder.up.3.block.2.conv1.weight', 'first_stage_model.decoder.up.3.block.2.conv1.bias', 'first_stage_model.decoder.up.3.block.2.norm2.weight', 'first_stage_model.decoder.up.3.block.2.norm2.bias', 'first_stage_model.decoder.up.3.block.2.conv2.weight', 'first_stage_model.decoder.up.3.block.2.conv2.bias', 'first_stage_model.decoder.up.3.upsample.conv.weight', 'first_stage_model.decoder.up.3.upsample.conv.bias', 'first_stage_model.decoder.norm_out.weight', 'first_stage_model.decoder.norm_out.bias', 'first_stage_model.decoder.conv_out.weight', 'first_stage_model.decoder.conv_out.bias', 'first_stage_model.quant_conv.weight', 'first_stage_model.quant_conv.bias', 'first_stage_model.post_quant_conv.weight', 'first_stage_model.post_quant_conv.bias', 'cond_stage_model.transformer.text_model.embeddings.position_ids', 'cond_stage_model.transformer.text_model.embeddings.token_embedding.weight', 'cond_stage_model.transformer.text_model.embeddings.position_embedding.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.bias', 'cond_stage_model.transformer.text_model.final_layer_norm.weight', 'cond_stage_model.transformer.text_model.final_layer_norm.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(test_weight.keys())\n",
    "convert_state_dict_to_jsonl(test_weight, \"sd_v1_4_weights.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b4a82419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 4, 3, 3])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_model.model.diffusion_model.input_blocks[0][0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d6d2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['cc_projection.weight', 'cc_projection.bias'], unexpected_keys=['model_ema.decay', 'model_ema.num_updates', 'cond_stage_model.transformer.text_model.embeddings.position_ids'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_model.load_state_dict(test_weight, strict=False)\n",
    "# 'cond_stage_model.transformer.text_model.embeddings.position_ids' 이것 말고는 적절하게 load된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87daf9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbcaa8f6",
   "metadata": {},
   "source": [
    "# ControlNet wieight 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f659c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_canny_path = os.path.join(\"/workspace/weight/diffuse/ControlNet/models\" ,\"control_sd15_canny.pth\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e7b580f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_net_ckpt = torch.load(control_canny_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "125106f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['betas', 'alphas_cumprod', 'alphas_cumprod_prev', 'sqrt_alphas_cumprod', 'sqrt_one_minus_alphas_cumprod', 'log_one_minus_alphas_cumprod', 'sqrt_recip_alphas_cumprod', 'sqrt_recipm1_alphas_cumprod', 'posterior_variance', 'posterior_log_variance_clipped', 'posterior_mean_coef1', 'posterior_mean_coef2', 'logvar', 'model.diffusion_model.time_embed.0.weight', 'model.diffusion_model.time_embed.0.bias', 'model.diffusion_model.time_embed.2.weight', 'model.diffusion_model.time_embed.2.bias', 'model.diffusion_model.input_blocks.0.0.weight', 'model.diffusion_model.input_blocks.0.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.1.1.norm.weight', 'model.diffusion_model.input_blocks.1.1.norm.bias', 'model.diffusion_model.input_blocks.1.1.proj_in.weight', 'model.diffusion_model.input_blocks.1.1.proj_in.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.1.1.proj_out.weight', 'model.diffusion_model.input_blocks.1.1.proj_out.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.2.1.norm.weight', 'model.diffusion_model.input_blocks.2.1.norm.bias', 'model.diffusion_model.input_blocks.2.1.proj_in.weight', 'model.diffusion_model.input_blocks.2.1.proj_in.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.2.1.proj_out.weight', 'model.diffusion_model.input_blocks.2.1.proj_out.bias', 'model.diffusion_model.input_blocks.3.0.op.weight', 'model.diffusion_model.input_blocks.3.0.op.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.4.0.skip_connection.weight', 'model.diffusion_model.input_blocks.4.0.skip_connection.bias', 'model.diffusion_model.input_blocks.4.1.norm.weight', 'model.diffusion_model.input_blocks.4.1.norm.bias', 'model.diffusion_model.input_blocks.4.1.proj_in.weight', 'model.diffusion_model.input_blocks.4.1.proj_in.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.4.1.proj_out.weight', 'model.diffusion_model.input_blocks.4.1.proj_out.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.5.1.norm.weight', 'model.diffusion_model.input_blocks.5.1.norm.bias', 'model.diffusion_model.input_blocks.5.1.proj_in.weight', 'model.diffusion_model.input_blocks.5.1.proj_in.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.5.1.proj_out.weight', 'model.diffusion_model.input_blocks.5.1.proj_out.bias', 'model.diffusion_model.input_blocks.6.0.op.weight', 'model.diffusion_model.input_blocks.6.0.op.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.7.0.skip_connection.weight', 'model.diffusion_model.input_blocks.7.0.skip_connection.bias', 'model.diffusion_model.input_blocks.7.1.norm.weight', 'model.diffusion_model.input_blocks.7.1.norm.bias', 'model.diffusion_model.input_blocks.7.1.proj_in.weight', 'model.diffusion_model.input_blocks.7.1.proj_in.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.7.1.proj_out.weight', 'model.diffusion_model.input_blocks.7.1.proj_out.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.8.1.norm.weight', 'model.diffusion_model.input_blocks.8.1.norm.bias', 'model.diffusion_model.input_blocks.8.1.proj_in.weight', 'model.diffusion_model.input_blocks.8.1.proj_in.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.input_blocks.8.1.proj_out.weight', 'model.diffusion_model.input_blocks.8.1.proj_out.bias', 'model.diffusion_model.input_blocks.9.0.op.weight', 'model.diffusion_model.input_blocks.9.0.op.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.input_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.input_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.input_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.input_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.middle_block.0.in_layers.0.weight', 'model.diffusion_model.middle_block.0.in_layers.0.bias', 'model.diffusion_model.middle_block.0.in_layers.2.weight', 'model.diffusion_model.middle_block.0.in_layers.2.bias', 'model.diffusion_model.middle_block.0.emb_layers.1.weight', 'model.diffusion_model.middle_block.0.emb_layers.1.bias', 'model.diffusion_model.middle_block.0.out_layers.0.weight', 'model.diffusion_model.middle_block.0.out_layers.0.bias', 'model.diffusion_model.middle_block.0.out_layers.3.weight', 'model.diffusion_model.middle_block.0.out_layers.3.bias', 'model.diffusion_model.middle_block.1.norm.weight', 'model.diffusion_model.middle_block.1.norm.bias', 'model.diffusion_model.middle_block.1.proj_in.weight', 'model.diffusion_model.middle_block.1.proj_in.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.middle_block.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.middle_block.1.proj_out.weight', 'model.diffusion_model.middle_block.1.proj_out.bias', 'model.diffusion_model.middle_block.2.in_layers.0.weight', 'model.diffusion_model.middle_block.2.in_layers.0.bias', 'model.diffusion_model.middle_block.2.in_layers.2.weight', 'model.diffusion_model.middle_block.2.in_layers.2.bias', 'model.diffusion_model.middle_block.2.emb_layers.1.weight', 'model.diffusion_model.middle_block.2.emb_layers.1.bias', 'model.diffusion_model.middle_block.2.out_layers.0.weight', 'model.diffusion_model.middle_block.2.out_layers.0.bias', 'model.diffusion_model.middle_block.2.out_layers.3.weight', 'model.diffusion_model.middle_block.2.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.0.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.0.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.0.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.0.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.0.0.skip_connection.weight', 'model.diffusion_model.output_blocks.0.0.skip_connection.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.1.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.1.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.1.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.1.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.1.0.skip_connection.weight', 'model.diffusion_model.output_blocks.1.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.2.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.2.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.2.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.2.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.2.0.skip_connection.weight', 'model.diffusion_model.output_blocks.2.0.skip_connection.bias', 'model.diffusion_model.output_blocks.2.1.conv.weight', 'model.diffusion_model.output_blocks.2.1.conv.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.3.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.3.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.3.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.3.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.3.0.skip_connection.weight', 'model.diffusion_model.output_blocks.3.0.skip_connection.bias', 'model.diffusion_model.output_blocks.3.1.norm.weight', 'model.diffusion_model.output_blocks.3.1.norm.bias', 'model.diffusion_model.output_blocks.3.1.proj_in.weight', 'model.diffusion_model.output_blocks.3.1.proj_in.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.3.1.proj_out.weight', 'model.diffusion_model.output_blocks.3.1.proj_out.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.4.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.4.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.4.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.4.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.4.0.skip_connection.weight', 'model.diffusion_model.output_blocks.4.0.skip_connection.bias', 'model.diffusion_model.output_blocks.4.1.norm.weight', 'model.diffusion_model.output_blocks.4.1.norm.bias', 'model.diffusion_model.output_blocks.4.1.proj_in.weight', 'model.diffusion_model.output_blocks.4.1.proj_in.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.4.1.proj_out.weight', 'model.diffusion_model.output_blocks.4.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.5.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.5.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.5.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.5.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.5.0.skip_connection.weight', 'model.diffusion_model.output_blocks.5.0.skip_connection.bias', 'model.diffusion_model.output_blocks.5.1.norm.weight', 'model.diffusion_model.output_blocks.5.1.norm.bias', 'model.diffusion_model.output_blocks.5.1.proj_in.weight', 'model.diffusion_model.output_blocks.5.1.proj_in.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.5.1.proj_out.weight', 'model.diffusion_model.output_blocks.5.1.proj_out.bias', 'model.diffusion_model.output_blocks.5.2.conv.weight', 'model.diffusion_model.output_blocks.5.2.conv.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.6.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.6.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.6.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.6.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.6.0.skip_connection.weight', 'model.diffusion_model.output_blocks.6.0.skip_connection.bias', 'model.diffusion_model.output_blocks.6.1.norm.weight', 'model.diffusion_model.output_blocks.6.1.norm.bias', 'model.diffusion_model.output_blocks.6.1.proj_in.weight', 'model.diffusion_model.output_blocks.6.1.proj_in.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.6.1.proj_out.weight', 'model.diffusion_model.output_blocks.6.1.proj_out.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.7.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.7.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.7.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.7.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.7.0.skip_connection.weight', 'model.diffusion_model.output_blocks.7.0.skip_connection.bias', 'model.diffusion_model.output_blocks.7.1.norm.weight', 'model.diffusion_model.output_blocks.7.1.norm.bias', 'model.diffusion_model.output_blocks.7.1.proj_in.weight', 'model.diffusion_model.output_blocks.7.1.proj_in.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.7.1.proj_out.weight', 'model.diffusion_model.output_blocks.7.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.8.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.8.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.8.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.8.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.8.0.skip_connection.weight', 'model.diffusion_model.output_blocks.8.0.skip_connection.bias', 'model.diffusion_model.output_blocks.8.1.norm.weight', 'model.diffusion_model.output_blocks.8.1.norm.bias', 'model.diffusion_model.output_blocks.8.1.proj_in.weight', 'model.diffusion_model.output_blocks.8.1.proj_in.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.8.1.proj_out.weight', 'model.diffusion_model.output_blocks.8.1.proj_out.bias', 'model.diffusion_model.output_blocks.8.2.conv.weight', 'model.diffusion_model.output_blocks.8.2.conv.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.9.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.9.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.9.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.9.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.9.0.skip_connection.weight', 'model.diffusion_model.output_blocks.9.0.skip_connection.bias', 'model.diffusion_model.output_blocks.9.1.norm.weight', 'model.diffusion_model.output_blocks.9.1.norm.bias', 'model.diffusion_model.output_blocks.9.1.proj_in.weight', 'model.diffusion_model.output_blocks.9.1.proj_in.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.9.1.proj_out.weight', 'model.diffusion_model.output_blocks.9.1.proj_out.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.10.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.10.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.10.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.10.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.10.0.skip_connection.weight', 'model.diffusion_model.output_blocks.10.0.skip_connection.bias', 'model.diffusion_model.output_blocks.10.1.norm.weight', 'model.diffusion_model.output_blocks.10.1.norm.bias', 'model.diffusion_model.output_blocks.10.1.proj_in.weight', 'model.diffusion_model.output_blocks.10.1.proj_in.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.10.1.proj_out.weight', 'model.diffusion_model.output_blocks.10.1.proj_out.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.in_layers.2.weight', 'model.diffusion_model.output_blocks.11.0.in_layers.2.bias', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.weight', 'model.diffusion_model.output_blocks.11.0.emb_layers.1.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.0.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.0.bias', 'model.diffusion_model.output_blocks.11.0.out_layers.3.weight', 'model.diffusion_model.output_blocks.11.0.out_layers.3.bias', 'model.diffusion_model.output_blocks.11.0.skip_connection.weight', 'model.diffusion_model.output_blocks.11.0.skip_connection.bias', 'model.diffusion_model.output_blocks.11.1.norm.weight', 'model.diffusion_model.output_blocks.11.1.norm.bias', 'model.diffusion_model.output_blocks.11.1.proj_in.weight', 'model.diffusion_model.output_blocks.11.1.proj_in.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.ff.net.2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_q.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm1.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm2.bias', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.weight', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.norm3.bias', 'model.diffusion_model.output_blocks.11.1.proj_out.weight', 'model.diffusion_model.output_blocks.11.1.proj_out.bias', 'model.diffusion_model.out.0.weight', 'model.diffusion_model.out.0.bias', 'model.diffusion_model.out.2.weight', 'model.diffusion_model.out.2.bias', 'first_stage_model.encoder.conv_in.weight', 'first_stage_model.encoder.conv_in.bias', 'first_stage_model.encoder.down.0.block.0.norm1.weight', 'first_stage_model.encoder.down.0.block.0.norm1.bias', 'first_stage_model.encoder.down.0.block.0.conv1.weight', 'first_stage_model.encoder.down.0.block.0.conv1.bias', 'first_stage_model.encoder.down.0.block.0.norm2.weight', 'first_stage_model.encoder.down.0.block.0.norm2.bias', 'first_stage_model.encoder.down.0.block.0.conv2.weight', 'first_stage_model.encoder.down.0.block.0.conv2.bias', 'first_stage_model.encoder.down.0.block.1.norm1.weight', 'first_stage_model.encoder.down.0.block.1.norm1.bias', 'first_stage_model.encoder.down.0.block.1.conv1.weight', 'first_stage_model.encoder.down.0.block.1.conv1.bias', 'first_stage_model.encoder.down.0.block.1.norm2.weight', 'first_stage_model.encoder.down.0.block.1.norm2.bias', 'first_stage_model.encoder.down.0.block.1.conv2.weight', 'first_stage_model.encoder.down.0.block.1.conv2.bias', 'first_stage_model.encoder.down.0.downsample.conv.weight', 'first_stage_model.encoder.down.0.downsample.conv.bias', 'first_stage_model.encoder.down.1.block.0.norm1.weight', 'first_stage_model.encoder.down.1.block.0.norm1.bias', 'first_stage_model.encoder.down.1.block.0.conv1.weight', 'first_stage_model.encoder.down.1.block.0.conv1.bias', 'first_stage_model.encoder.down.1.block.0.norm2.weight', 'first_stage_model.encoder.down.1.block.0.norm2.bias', 'first_stage_model.encoder.down.1.block.0.conv2.weight', 'first_stage_model.encoder.down.1.block.0.conv2.bias', 'first_stage_model.encoder.down.1.block.0.nin_shortcut.weight', 'first_stage_model.encoder.down.1.block.0.nin_shortcut.bias', 'first_stage_model.encoder.down.1.block.1.norm1.weight', 'first_stage_model.encoder.down.1.block.1.norm1.bias', 'first_stage_model.encoder.down.1.block.1.conv1.weight', 'first_stage_model.encoder.down.1.block.1.conv1.bias', 'first_stage_model.encoder.down.1.block.1.norm2.weight', 'first_stage_model.encoder.down.1.block.1.norm2.bias', 'first_stage_model.encoder.down.1.block.1.conv2.weight', 'first_stage_model.encoder.down.1.block.1.conv2.bias', 'first_stage_model.encoder.down.1.downsample.conv.weight', 'first_stage_model.encoder.down.1.downsample.conv.bias', 'first_stage_model.encoder.down.2.block.0.norm1.weight', 'first_stage_model.encoder.down.2.block.0.norm1.bias', 'first_stage_model.encoder.down.2.block.0.conv1.weight', 'first_stage_model.encoder.down.2.block.0.conv1.bias', 'first_stage_model.encoder.down.2.block.0.norm2.weight', 'first_stage_model.encoder.down.2.block.0.norm2.bias', 'first_stage_model.encoder.down.2.block.0.conv2.weight', 'first_stage_model.encoder.down.2.block.0.conv2.bias', 'first_stage_model.encoder.down.2.block.0.nin_shortcut.weight', 'first_stage_model.encoder.down.2.block.0.nin_shortcut.bias', 'first_stage_model.encoder.down.2.block.1.norm1.weight', 'first_stage_model.encoder.down.2.block.1.norm1.bias', 'first_stage_model.encoder.down.2.block.1.conv1.weight', 'first_stage_model.encoder.down.2.block.1.conv1.bias', 'first_stage_model.encoder.down.2.block.1.norm2.weight', 'first_stage_model.encoder.down.2.block.1.norm2.bias', 'first_stage_model.encoder.down.2.block.1.conv2.weight', 'first_stage_model.encoder.down.2.block.1.conv2.bias', 'first_stage_model.encoder.down.2.downsample.conv.weight', 'first_stage_model.encoder.down.2.downsample.conv.bias', 'first_stage_model.encoder.down.3.block.0.norm1.weight', 'first_stage_model.encoder.down.3.block.0.norm1.bias', 'first_stage_model.encoder.down.3.block.0.conv1.weight', 'first_stage_model.encoder.down.3.block.0.conv1.bias', 'first_stage_model.encoder.down.3.block.0.norm2.weight', 'first_stage_model.encoder.down.3.block.0.norm2.bias', 'first_stage_model.encoder.down.3.block.0.conv2.weight', 'first_stage_model.encoder.down.3.block.0.conv2.bias', 'first_stage_model.encoder.down.3.block.1.norm1.weight', 'first_stage_model.encoder.down.3.block.1.norm1.bias', 'first_stage_model.encoder.down.3.block.1.conv1.weight', 'first_stage_model.encoder.down.3.block.1.conv1.bias', 'first_stage_model.encoder.down.3.block.1.norm2.weight', 'first_stage_model.encoder.down.3.block.1.norm2.bias', 'first_stage_model.encoder.down.3.block.1.conv2.weight', 'first_stage_model.encoder.down.3.block.1.conv2.bias', 'first_stage_model.encoder.mid.block_1.norm1.weight', 'first_stage_model.encoder.mid.block_1.norm1.bias', 'first_stage_model.encoder.mid.block_1.conv1.weight', 'first_stage_model.encoder.mid.block_1.conv1.bias', 'first_stage_model.encoder.mid.block_1.norm2.weight', 'first_stage_model.encoder.mid.block_1.norm2.bias', 'first_stage_model.encoder.mid.block_1.conv2.weight', 'first_stage_model.encoder.mid.block_1.conv2.bias', 'first_stage_model.encoder.mid.attn_1.norm.weight', 'first_stage_model.encoder.mid.attn_1.norm.bias', 'first_stage_model.encoder.mid.attn_1.q.weight', 'first_stage_model.encoder.mid.attn_1.q.bias', 'first_stage_model.encoder.mid.attn_1.k.weight', 'first_stage_model.encoder.mid.attn_1.k.bias', 'first_stage_model.encoder.mid.attn_1.v.weight', 'first_stage_model.encoder.mid.attn_1.v.bias', 'first_stage_model.encoder.mid.attn_1.proj_out.weight', 'first_stage_model.encoder.mid.attn_1.proj_out.bias', 'first_stage_model.encoder.mid.block_2.norm1.weight', 'first_stage_model.encoder.mid.block_2.norm1.bias', 'first_stage_model.encoder.mid.block_2.conv1.weight', 'first_stage_model.encoder.mid.block_2.conv1.bias', 'first_stage_model.encoder.mid.block_2.norm2.weight', 'first_stage_model.encoder.mid.block_2.norm2.bias', 'first_stage_model.encoder.mid.block_2.conv2.weight', 'first_stage_model.encoder.mid.block_2.conv2.bias', 'first_stage_model.encoder.norm_out.weight', 'first_stage_model.encoder.norm_out.bias', 'first_stage_model.encoder.conv_out.weight', 'first_stage_model.encoder.conv_out.bias', 'first_stage_model.decoder.conv_in.weight', 'first_stage_model.decoder.conv_in.bias', 'first_stage_model.decoder.mid.block_1.norm1.weight', 'first_stage_model.decoder.mid.block_1.norm1.bias', 'first_stage_model.decoder.mid.block_1.conv1.weight', 'first_stage_model.decoder.mid.block_1.conv1.bias', 'first_stage_model.decoder.mid.block_1.norm2.weight', 'first_stage_model.decoder.mid.block_1.norm2.bias', 'first_stage_model.decoder.mid.block_1.conv2.weight', 'first_stage_model.decoder.mid.block_1.conv2.bias', 'first_stage_model.decoder.mid.attn_1.norm.weight', 'first_stage_model.decoder.mid.attn_1.norm.bias', 'first_stage_model.decoder.mid.attn_1.q.weight', 'first_stage_model.decoder.mid.attn_1.q.bias', 'first_stage_model.decoder.mid.attn_1.k.weight', 'first_stage_model.decoder.mid.attn_1.k.bias', 'first_stage_model.decoder.mid.attn_1.v.weight', 'first_stage_model.decoder.mid.attn_1.v.bias', 'first_stage_model.decoder.mid.attn_1.proj_out.weight', 'first_stage_model.decoder.mid.attn_1.proj_out.bias', 'first_stage_model.decoder.mid.block_2.norm1.weight', 'first_stage_model.decoder.mid.block_2.norm1.bias', 'first_stage_model.decoder.mid.block_2.conv1.weight', 'first_stage_model.decoder.mid.block_2.conv1.bias', 'first_stage_model.decoder.mid.block_2.norm2.weight', 'first_stage_model.decoder.mid.block_2.norm2.bias', 'first_stage_model.decoder.mid.block_2.conv2.weight', 'first_stage_model.decoder.mid.block_2.conv2.bias', 'first_stage_model.decoder.up.0.block.0.norm1.weight', 'first_stage_model.decoder.up.0.block.0.norm1.bias', 'first_stage_model.decoder.up.0.block.0.conv1.weight', 'first_stage_model.decoder.up.0.block.0.conv1.bias', 'first_stage_model.decoder.up.0.block.0.norm2.weight', 'first_stage_model.decoder.up.0.block.0.norm2.bias', 'first_stage_model.decoder.up.0.block.0.conv2.weight', 'first_stage_model.decoder.up.0.block.0.conv2.bias', 'first_stage_model.decoder.up.0.block.0.nin_shortcut.weight', 'first_stage_model.decoder.up.0.block.0.nin_shortcut.bias', 'first_stage_model.decoder.up.0.block.1.norm1.weight', 'first_stage_model.decoder.up.0.block.1.norm1.bias', 'first_stage_model.decoder.up.0.block.1.conv1.weight', 'first_stage_model.decoder.up.0.block.1.conv1.bias', 'first_stage_model.decoder.up.0.block.1.norm2.weight', 'first_stage_model.decoder.up.0.block.1.norm2.bias', 'first_stage_model.decoder.up.0.block.1.conv2.weight', 'first_stage_model.decoder.up.0.block.1.conv2.bias', 'first_stage_model.decoder.up.0.block.2.norm1.weight', 'first_stage_model.decoder.up.0.block.2.norm1.bias', 'first_stage_model.decoder.up.0.block.2.conv1.weight', 'first_stage_model.decoder.up.0.block.2.conv1.bias', 'first_stage_model.decoder.up.0.block.2.norm2.weight', 'first_stage_model.decoder.up.0.block.2.norm2.bias', 'first_stage_model.decoder.up.0.block.2.conv2.weight', 'first_stage_model.decoder.up.0.block.2.conv2.bias', 'first_stage_model.decoder.up.1.block.0.norm1.weight', 'first_stage_model.decoder.up.1.block.0.norm1.bias', 'first_stage_model.decoder.up.1.block.0.conv1.weight', 'first_stage_model.decoder.up.1.block.0.conv1.bias', 'first_stage_model.decoder.up.1.block.0.norm2.weight', 'first_stage_model.decoder.up.1.block.0.norm2.bias', 'first_stage_model.decoder.up.1.block.0.conv2.weight', 'first_stage_model.decoder.up.1.block.0.conv2.bias', 'first_stage_model.decoder.up.1.block.0.nin_shortcut.weight', 'first_stage_model.decoder.up.1.block.0.nin_shortcut.bias', 'first_stage_model.decoder.up.1.block.1.norm1.weight', 'first_stage_model.decoder.up.1.block.1.norm1.bias', 'first_stage_model.decoder.up.1.block.1.conv1.weight', 'first_stage_model.decoder.up.1.block.1.conv1.bias', 'first_stage_model.decoder.up.1.block.1.norm2.weight', 'first_stage_model.decoder.up.1.block.1.norm2.bias', 'first_stage_model.decoder.up.1.block.1.conv2.weight', 'first_stage_model.decoder.up.1.block.1.conv2.bias', 'first_stage_model.decoder.up.1.block.2.norm1.weight', 'first_stage_model.decoder.up.1.block.2.norm1.bias', 'first_stage_model.decoder.up.1.block.2.conv1.weight', 'first_stage_model.decoder.up.1.block.2.conv1.bias', 'first_stage_model.decoder.up.1.block.2.norm2.weight', 'first_stage_model.decoder.up.1.block.2.norm2.bias', 'first_stage_model.decoder.up.1.block.2.conv2.weight', 'first_stage_model.decoder.up.1.block.2.conv2.bias', 'first_stage_model.decoder.up.1.upsample.conv.weight', 'first_stage_model.decoder.up.1.upsample.conv.bias', 'first_stage_model.decoder.up.2.block.0.norm1.weight', 'first_stage_model.decoder.up.2.block.0.norm1.bias', 'first_stage_model.decoder.up.2.block.0.conv1.weight', 'first_stage_model.decoder.up.2.block.0.conv1.bias', 'first_stage_model.decoder.up.2.block.0.norm2.weight', 'first_stage_model.decoder.up.2.block.0.norm2.bias', 'first_stage_model.decoder.up.2.block.0.conv2.weight', 'first_stage_model.decoder.up.2.block.0.conv2.bias', 'first_stage_model.decoder.up.2.block.1.norm1.weight', 'first_stage_model.decoder.up.2.block.1.norm1.bias', 'first_stage_model.decoder.up.2.block.1.conv1.weight', 'first_stage_model.decoder.up.2.block.1.conv1.bias', 'first_stage_model.decoder.up.2.block.1.norm2.weight', 'first_stage_model.decoder.up.2.block.1.norm2.bias', 'first_stage_model.decoder.up.2.block.1.conv2.weight', 'first_stage_model.decoder.up.2.block.1.conv2.bias', 'first_stage_model.decoder.up.2.block.2.norm1.weight', 'first_stage_model.decoder.up.2.block.2.norm1.bias', 'first_stage_model.decoder.up.2.block.2.conv1.weight', 'first_stage_model.decoder.up.2.block.2.conv1.bias', 'first_stage_model.decoder.up.2.block.2.norm2.weight', 'first_stage_model.decoder.up.2.block.2.norm2.bias', 'first_stage_model.decoder.up.2.block.2.conv2.weight', 'first_stage_model.decoder.up.2.block.2.conv2.bias', 'first_stage_model.decoder.up.2.upsample.conv.weight', 'first_stage_model.decoder.up.2.upsample.conv.bias', 'first_stage_model.decoder.up.3.block.0.norm1.weight', 'first_stage_model.decoder.up.3.block.0.norm1.bias', 'first_stage_model.decoder.up.3.block.0.conv1.weight', 'first_stage_model.decoder.up.3.block.0.conv1.bias', 'first_stage_model.decoder.up.3.block.0.norm2.weight', 'first_stage_model.decoder.up.3.block.0.norm2.bias', 'first_stage_model.decoder.up.3.block.0.conv2.weight', 'first_stage_model.decoder.up.3.block.0.conv2.bias', 'first_stage_model.decoder.up.3.block.1.norm1.weight', 'first_stage_model.decoder.up.3.block.1.norm1.bias', 'first_stage_model.decoder.up.3.block.1.conv1.weight', 'first_stage_model.decoder.up.3.block.1.conv1.bias', 'first_stage_model.decoder.up.3.block.1.norm2.weight', 'first_stage_model.decoder.up.3.block.1.norm2.bias', 'first_stage_model.decoder.up.3.block.1.conv2.weight', 'first_stage_model.decoder.up.3.block.1.conv2.bias', 'first_stage_model.decoder.up.3.block.2.norm1.weight', 'first_stage_model.decoder.up.3.block.2.norm1.bias', 'first_stage_model.decoder.up.3.block.2.conv1.weight', 'first_stage_model.decoder.up.3.block.2.conv1.bias', 'first_stage_model.decoder.up.3.block.2.norm2.weight', 'first_stage_model.decoder.up.3.block.2.norm2.bias', 'first_stage_model.decoder.up.3.block.2.conv2.weight', 'first_stage_model.decoder.up.3.block.2.conv2.bias', 'first_stage_model.decoder.up.3.upsample.conv.weight', 'first_stage_model.decoder.up.3.upsample.conv.bias', 'first_stage_model.decoder.norm_out.weight', 'first_stage_model.decoder.norm_out.bias', 'first_stage_model.decoder.conv_out.weight', 'first_stage_model.decoder.conv_out.bias', 'first_stage_model.quant_conv.weight', 'first_stage_model.quant_conv.bias', 'first_stage_model.post_quant_conv.weight', 'first_stage_model.post_quant_conv.bias', 'cond_stage_model.transformer.text_model.embeddings.position_ids', 'cond_stage_model.transformer.text_model.embeddings.token_embedding.weight', 'cond_stage_model.transformer.text_model.embeddings.position_embedding.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.0.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.1.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.2.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.3.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.4.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.5.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.6.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.7.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.8.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.9.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.10.layer_norm2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.k_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.v_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.q_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.self_attn.out_proj.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc1.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.mlp.fc2.bias', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.weight', 'cond_stage_model.transformer.text_model.encoder.layers.11.layer_norm2.bias', 'cond_stage_model.transformer.text_model.final_layer_norm.weight', 'cond_stage_model.transformer.text_model.final_layer_norm.bias', 'control_model.time_embed.0.weight', 'control_model.time_embed.0.bias', 'control_model.time_embed.2.weight', 'control_model.time_embed.2.bias', 'control_model.input_blocks.0.0.weight', 'control_model.input_blocks.0.0.bias', 'control_model.input_blocks.1.0.in_layers.0.weight', 'control_model.input_blocks.1.0.in_layers.0.bias', 'control_model.input_blocks.1.0.in_layers.2.weight', 'control_model.input_blocks.1.0.in_layers.2.bias', 'control_model.input_blocks.1.0.emb_layers.1.weight', 'control_model.input_blocks.1.0.emb_layers.1.bias', 'control_model.input_blocks.1.0.out_layers.0.weight', 'control_model.input_blocks.1.0.out_layers.0.bias', 'control_model.input_blocks.1.0.out_layers.3.weight', 'control_model.input_blocks.1.0.out_layers.3.bias', 'control_model.input_blocks.1.1.norm.weight', 'control_model.input_blocks.1.1.norm.bias', 'control_model.input_blocks.1.1.proj_in.weight', 'control_model.input_blocks.1.1.proj_in.bias', 'control_model.input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight', 'control_model.input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight', 'control_model.input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight', 'control_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight', 'control_model.input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias', 'control_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight', 'control_model.input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias', 'control_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.weight', 'control_model.input_blocks.1.1.transformer_blocks.0.ff.net.2.bias', 'control_model.input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight', 'control_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight', 'control_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight', 'control_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight', 'control_model.input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias', 'control_model.input_blocks.1.1.transformer_blocks.0.norm1.weight', 'control_model.input_blocks.1.1.transformer_blocks.0.norm1.bias', 'control_model.input_blocks.1.1.transformer_blocks.0.norm2.weight', 'control_model.input_blocks.1.1.transformer_blocks.0.norm2.bias', 'control_model.input_blocks.1.1.transformer_blocks.0.norm3.weight', 'control_model.input_blocks.1.1.transformer_blocks.0.norm3.bias', 'control_model.input_blocks.1.1.proj_out.weight', 'control_model.input_blocks.1.1.proj_out.bias', 'control_model.input_blocks.2.0.in_layers.0.weight', 'control_model.input_blocks.2.0.in_layers.0.bias', 'control_model.input_blocks.2.0.in_layers.2.weight', 'control_model.input_blocks.2.0.in_layers.2.bias', 'control_model.input_blocks.2.0.emb_layers.1.weight', 'control_model.input_blocks.2.0.emb_layers.1.bias', 'control_model.input_blocks.2.0.out_layers.0.weight', 'control_model.input_blocks.2.0.out_layers.0.bias', 'control_model.input_blocks.2.0.out_layers.3.weight', 'control_model.input_blocks.2.0.out_layers.3.bias', 'control_model.input_blocks.2.1.norm.weight', 'control_model.input_blocks.2.1.norm.bias', 'control_model.input_blocks.2.1.proj_in.weight', 'control_model.input_blocks.2.1.proj_in.bias', 'control_model.input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight', 'control_model.input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight', 'control_model.input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight', 'control_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight', 'control_model.input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias', 'control_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight', 'control_model.input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias', 'control_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.weight', 'control_model.input_blocks.2.1.transformer_blocks.0.ff.net.2.bias', 'control_model.input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight', 'control_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight', 'control_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight', 'control_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight', 'control_model.input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias', 'control_model.input_blocks.2.1.transformer_blocks.0.norm1.weight', 'control_model.input_blocks.2.1.transformer_blocks.0.norm1.bias', 'control_model.input_blocks.2.1.transformer_blocks.0.norm2.weight', 'control_model.input_blocks.2.1.transformer_blocks.0.norm2.bias', 'control_model.input_blocks.2.1.transformer_blocks.0.norm3.weight', 'control_model.input_blocks.2.1.transformer_blocks.0.norm3.bias', 'control_model.input_blocks.2.1.proj_out.weight', 'control_model.input_blocks.2.1.proj_out.bias', 'control_model.input_blocks.3.0.op.weight', 'control_model.input_blocks.3.0.op.bias', 'control_model.input_blocks.4.0.in_layers.0.weight', 'control_model.input_blocks.4.0.in_layers.0.bias', 'control_model.input_blocks.4.0.in_layers.2.weight', 'control_model.input_blocks.4.0.in_layers.2.bias', 'control_model.input_blocks.4.0.emb_layers.1.weight', 'control_model.input_blocks.4.0.emb_layers.1.bias', 'control_model.input_blocks.4.0.out_layers.0.weight', 'control_model.input_blocks.4.0.out_layers.0.bias', 'control_model.input_blocks.4.0.out_layers.3.weight', 'control_model.input_blocks.4.0.out_layers.3.bias', 'control_model.input_blocks.4.0.skip_connection.weight', 'control_model.input_blocks.4.0.skip_connection.bias', 'control_model.input_blocks.4.1.norm.weight', 'control_model.input_blocks.4.1.norm.bias', 'control_model.input_blocks.4.1.proj_in.weight', 'control_model.input_blocks.4.1.proj_in.bias', 'control_model.input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight', 'control_model.input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight', 'control_model.input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight', 'control_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight', 'control_model.input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias', 'control_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight', 'control_model.input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias', 'control_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.weight', 'control_model.input_blocks.4.1.transformer_blocks.0.ff.net.2.bias', 'control_model.input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight', 'control_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight', 'control_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight', 'control_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight', 'control_model.input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias', 'control_model.input_blocks.4.1.transformer_blocks.0.norm1.weight', 'control_model.input_blocks.4.1.transformer_blocks.0.norm1.bias', 'control_model.input_blocks.4.1.transformer_blocks.0.norm2.weight', 'control_model.input_blocks.4.1.transformer_blocks.0.norm2.bias', 'control_model.input_blocks.4.1.transformer_blocks.0.norm3.weight', 'control_model.input_blocks.4.1.transformer_blocks.0.norm3.bias', 'control_model.input_blocks.4.1.proj_out.weight', 'control_model.input_blocks.4.1.proj_out.bias', 'control_model.input_blocks.5.0.in_layers.0.weight', 'control_model.input_blocks.5.0.in_layers.0.bias', 'control_model.input_blocks.5.0.in_layers.2.weight', 'control_model.input_blocks.5.0.in_layers.2.bias', 'control_model.input_blocks.5.0.emb_layers.1.weight', 'control_model.input_blocks.5.0.emb_layers.1.bias', 'control_model.input_blocks.5.0.out_layers.0.weight', 'control_model.input_blocks.5.0.out_layers.0.bias', 'control_model.input_blocks.5.0.out_layers.3.weight', 'control_model.input_blocks.5.0.out_layers.3.bias', 'control_model.input_blocks.5.1.norm.weight', 'control_model.input_blocks.5.1.norm.bias', 'control_model.input_blocks.5.1.proj_in.weight', 'control_model.input_blocks.5.1.proj_in.bias', 'control_model.input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight', 'control_model.input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight', 'control_model.input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight', 'control_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight', 'control_model.input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias', 'control_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight', 'control_model.input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias', 'control_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.weight', 'control_model.input_blocks.5.1.transformer_blocks.0.ff.net.2.bias', 'control_model.input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight', 'control_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight', 'control_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight', 'control_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight', 'control_model.input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias', 'control_model.input_blocks.5.1.transformer_blocks.0.norm1.weight', 'control_model.input_blocks.5.1.transformer_blocks.0.norm1.bias', 'control_model.input_blocks.5.1.transformer_blocks.0.norm2.weight', 'control_model.input_blocks.5.1.transformer_blocks.0.norm2.bias', 'control_model.input_blocks.5.1.transformer_blocks.0.norm3.weight', 'control_model.input_blocks.5.1.transformer_blocks.0.norm3.bias', 'control_model.input_blocks.5.1.proj_out.weight', 'control_model.input_blocks.5.1.proj_out.bias', 'control_model.input_blocks.6.0.op.weight', 'control_model.input_blocks.6.0.op.bias', 'control_model.input_blocks.7.0.in_layers.0.weight', 'control_model.input_blocks.7.0.in_layers.0.bias', 'control_model.input_blocks.7.0.in_layers.2.weight', 'control_model.input_blocks.7.0.in_layers.2.bias', 'control_model.input_blocks.7.0.emb_layers.1.weight', 'control_model.input_blocks.7.0.emb_layers.1.bias', 'control_model.input_blocks.7.0.out_layers.0.weight', 'control_model.input_blocks.7.0.out_layers.0.bias', 'control_model.input_blocks.7.0.out_layers.3.weight', 'control_model.input_blocks.7.0.out_layers.3.bias', 'control_model.input_blocks.7.0.skip_connection.weight', 'control_model.input_blocks.7.0.skip_connection.bias', 'control_model.input_blocks.7.1.norm.weight', 'control_model.input_blocks.7.1.norm.bias', 'control_model.input_blocks.7.1.proj_in.weight', 'control_model.input_blocks.7.1.proj_in.bias', 'control_model.input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight', 'control_model.input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight', 'control_model.input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight', 'control_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight', 'control_model.input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias', 'control_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight', 'control_model.input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias', 'control_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.weight', 'control_model.input_blocks.7.1.transformer_blocks.0.ff.net.2.bias', 'control_model.input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight', 'control_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight', 'control_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight', 'control_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight', 'control_model.input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias', 'control_model.input_blocks.7.1.transformer_blocks.0.norm1.weight', 'control_model.input_blocks.7.1.transformer_blocks.0.norm1.bias', 'control_model.input_blocks.7.1.transformer_blocks.0.norm2.weight', 'control_model.input_blocks.7.1.transformer_blocks.0.norm2.bias', 'control_model.input_blocks.7.1.transformer_blocks.0.norm3.weight', 'control_model.input_blocks.7.1.transformer_blocks.0.norm3.bias', 'control_model.input_blocks.7.1.proj_out.weight', 'control_model.input_blocks.7.1.proj_out.bias', 'control_model.input_blocks.8.0.in_layers.0.weight', 'control_model.input_blocks.8.0.in_layers.0.bias', 'control_model.input_blocks.8.0.in_layers.2.weight', 'control_model.input_blocks.8.0.in_layers.2.bias', 'control_model.input_blocks.8.0.emb_layers.1.weight', 'control_model.input_blocks.8.0.emb_layers.1.bias', 'control_model.input_blocks.8.0.out_layers.0.weight', 'control_model.input_blocks.8.0.out_layers.0.bias', 'control_model.input_blocks.8.0.out_layers.3.weight', 'control_model.input_blocks.8.0.out_layers.3.bias', 'control_model.input_blocks.8.1.norm.weight', 'control_model.input_blocks.8.1.norm.bias', 'control_model.input_blocks.8.1.proj_in.weight', 'control_model.input_blocks.8.1.proj_in.bias', 'control_model.input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight', 'control_model.input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight', 'control_model.input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight', 'control_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight', 'control_model.input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias', 'control_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight', 'control_model.input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias', 'control_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.weight', 'control_model.input_blocks.8.1.transformer_blocks.0.ff.net.2.bias', 'control_model.input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight', 'control_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight', 'control_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight', 'control_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight', 'control_model.input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias', 'control_model.input_blocks.8.1.transformer_blocks.0.norm1.weight', 'control_model.input_blocks.8.1.transformer_blocks.0.norm1.bias', 'control_model.input_blocks.8.1.transformer_blocks.0.norm2.weight', 'control_model.input_blocks.8.1.transformer_blocks.0.norm2.bias', 'control_model.input_blocks.8.1.transformer_blocks.0.norm3.weight', 'control_model.input_blocks.8.1.transformer_blocks.0.norm3.bias', 'control_model.input_blocks.8.1.proj_out.weight', 'control_model.input_blocks.8.1.proj_out.bias', 'control_model.input_blocks.9.0.op.weight', 'control_model.input_blocks.9.0.op.bias', 'control_model.input_blocks.10.0.in_layers.0.weight', 'control_model.input_blocks.10.0.in_layers.0.bias', 'control_model.input_blocks.10.0.in_layers.2.weight', 'control_model.input_blocks.10.0.in_layers.2.bias', 'control_model.input_blocks.10.0.emb_layers.1.weight', 'control_model.input_blocks.10.0.emb_layers.1.bias', 'control_model.input_blocks.10.0.out_layers.0.weight', 'control_model.input_blocks.10.0.out_layers.0.bias', 'control_model.input_blocks.10.0.out_layers.3.weight', 'control_model.input_blocks.10.0.out_layers.3.bias', 'control_model.input_blocks.11.0.in_layers.0.weight', 'control_model.input_blocks.11.0.in_layers.0.bias', 'control_model.input_blocks.11.0.in_layers.2.weight', 'control_model.input_blocks.11.0.in_layers.2.bias', 'control_model.input_blocks.11.0.emb_layers.1.weight', 'control_model.input_blocks.11.0.emb_layers.1.bias', 'control_model.input_blocks.11.0.out_layers.0.weight', 'control_model.input_blocks.11.0.out_layers.0.bias', 'control_model.input_blocks.11.0.out_layers.3.weight', 'control_model.input_blocks.11.0.out_layers.3.bias', 'control_model.zero_convs.0.0.weight', 'control_model.zero_convs.0.0.bias', 'control_model.zero_convs.1.0.weight', 'control_model.zero_convs.1.0.bias', 'control_model.zero_convs.2.0.weight', 'control_model.zero_convs.2.0.bias', 'control_model.zero_convs.3.0.weight', 'control_model.zero_convs.3.0.bias', 'control_model.zero_convs.4.0.weight', 'control_model.zero_convs.4.0.bias', 'control_model.zero_convs.5.0.weight', 'control_model.zero_convs.5.0.bias', 'control_model.zero_convs.6.0.weight', 'control_model.zero_convs.6.0.bias', 'control_model.zero_convs.7.0.weight', 'control_model.zero_convs.7.0.bias', 'control_model.zero_convs.8.0.weight', 'control_model.zero_convs.8.0.bias', 'control_model.zero_convs.9.0.weight', 'control_model.zero_convs.9.0.bias', 'control_model.zero_convs.10.0.weight', 'control_model.zero_convs.10.0.bias', 'control_model.zero_convs.11.0.weight', 'control_model.zero_convs.11.0.bias', 'control_model.input_hint_block.0.weight', 'control_model.input_hint_block.0.bias', 'control_model.input_hint_block.2.weight', 'control_model.input_hint_block.2.bias', 'control_model.input_hint_block.4.weight', 'control_model.input_hint_block.4.bias', 'control_model.input_hint_block.6.weight', 'control_model.input_hint_block.6.bias', 'control_model.input_hint_block.8.weight', 'control_model.input_hint_block.8.bias', 'control_model.input_hint_block.10.weight', 'control_model.input_hint_block.10.bias', 'control_model.input_hint_block.12.weight', 'control_model.input_hint_block.12.bias', 'control_model.input_hint_block.14.weight', 'control_model.input_hint_block.14.bias', 'control_model.middle_block.0.in_layers.0.weight', 'control_model.middle_block.0.in_layers.0.bias', 'control_model.middle_block.0.in_layers.2.weight', 'control_model.middle_block.0.in_layers.2.bias', 'control_model.middle_block.0.emb_layers.1.weight', 'control_model.middle_block.0.emb_layers.1.bias', 'control_model.middle_block.0.out_layers.0.weight', 'control_model.middle_block.0.out_layers.0.bias', 'control_model.middle_block.0.out_layers.3.weight', 'control_model.middle_block.0.out_layers.3.bias', 'control_model.middle_block.1.norm.weight', 'control_model.middle_block.1.norm.bias', 'control_model.middle_block.1.proj_in.weight', 'control_model.middle_block.1.proj_in.bias', 'control_model.middle_block.1.transformer_blocks.0.attn1.to_q.weight', 'control_model.middle_block.1.transformer_blocks.0.attn1.to_k.weight', 'control_model.middle_block.1.transformer_blocks.0.attn1.to_v.weight', 'control_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.weight', 'control_model.middle_block.1.transformer_blocks.0.attn1.to_out.0.bias', 'control_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.weight', 'control_model.middle_block.1.transformer_blocks.0.ff.net.0.proj.bias', 'control_model.middle_block.1.transformer_blocks.0.ff.net.2.weight', 'control_model.middle_block.1.transformer_blocks.0.ff.net.2.bias', 'control_model.middle_block.1.transformer_blocks.0.attn2.to_q.weight', 'control_model.middle_block.1.transformer_blocks.0.attn2.to_k.weight', 'control_model.middle_block.1.transformer_blocks.0.attn2.to_v.weight', 'control_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.weight', 'control_model.middle_block.1.transformer_blocks.0.attn2.to_out.0.bias', 'control_model.middle_block.1.transformer_blocks.0.norm1.weight', 'control_model.middle_block.1.transformer_blocks.0.norm1.bias', 'control_model.middle_block.1.transformer_blocks.0.norm2.weight', 'control_model.middle_block.1.transformer_blocks.0.norm2.bias', 'control_model.middle_block.1.transformer_blocks.0.norm3.weight', 'control_model.middle_block.1.transformer_blocks.0.norm3.bias', 'control_model.middle_block.1.proj_out.weight', 'control_model.middle_block.1.proj_out.bias', 'control_model.middle_block.2.in_layers.0.weight', 'control_model.middle_block.2.in_layers.0.bias', 'control_model.middle_block.2.in_layers.2.weight', 'control_model.middle_block.2.in_layers.2.bias', 'control_model.middle_block.2.emb_layers.1.weight', 'control_model.middle_block.2.emb_layers.1.bias', 'control_model.middle_block.2.out_layers.0.weight', 'control_model.middle_block.2.out_layers.0.bias', 'control_model.middle_block.2.out_layers.3.weight', 'control_model.middle_block.2.out_layers.3.bias', 'control_model.middle_block_out.0.weight', 'control_model.middle_block_out.0.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(control_net_ckpt.keys())\n",
    "convert_state_dict_to_jsonl(control_net_ckpt, \"control_sd15_canny_weights.jsonl\")\n",
    "# json으로 따서 보기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
