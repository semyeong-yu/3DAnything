{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed96f1a5",
   "metadata": {},
   "source": [
    "- row는 num images\n",
    "- col은 (input, output, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48fcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee9b4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import json\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader, Dataset, Subset\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "from ldm.util import instantiate_from_config\n",
    "from easydict import EasyDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a9e53f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/workspace/code/3DAnything/zero123/configs/normal_variant_i2t_multimodal_v3_256.yaml\"\n",
    "target_cfg = OmegaConf.load(config_path)\n",
    "weight_path = \"/workspace/code/3DAnything/zero123/results/2025-06-11T18-53-14_normal_variant_i2t_multimodal_v3_256/checkpoints/epoch=000117.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41058f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'normal_variant_i2t_multimodal_v3_256'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(config_path).split('.')[0]  # get the name of the config file without extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e59fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_unbind(tensor):\n",
    "    # torch.unbind removes the specified dimension (0 = batch) and returns a tuple\n",
    "    individual_images = torch.unbind(tensor, dim=0)  # Returns tuple of 64 tensors\n",
    "    return list(individual_images)  # Convert tuple to list for consistency\n",
    "\n",
    "def convert_to_npy(tensor_list):\n",
    "    new_list = []\n",
    "    for each_tensor in tensor_list:\n",
    "        img = each_tensor.clamp(-1, 1)\n",
    "        img = (img + 1.0) / 2\n",
    "        img = img.permute(1, 2, 0)\n",
    "        img_np = img.numpy()\n",
    "        new_list.append(img_np)\n",
    "    return new_list\n",
    "\n",
    "def plot_image(image_tensor):\n",
    "    # Assuming image is normalized; adjust if necessary\n",
    "    img = image_tensor.cpu().clone()\n",
    "    img = img.clamp(-1, 1)\n",
    "    img = (img + 1.0)/2  # Example denormalization\n",
    "    \n",
    "    # Permute dimensions: [3, 256, 256] -> [256, 256, 3]\n",
    "    img = img.permute(1, 2, 0)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    img_np = img.numpy()\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(img_np)\n",
    "    plt.axis('off')\n",
    "    plt.title('Individual Image')\n",
    "    plt.show()\n",
    "\n",
    "def total_writer(dir:str, ret_dict: dict, cfg_scale: float = 3.0):\n",
    "    # Image.fromarray((proc_result[\"samples_cfg_scale_3.00\"][0] * 255).astype(\"uint8\")).show()\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    image_target_list = [\"inputs\", \"reconstruction\", \"control\", f\"samples_cfg_scale_{cfg_scale:.2f}\"] \n",
    "    \n",
    "    for sub_dir in image_target_list:\n",
    "        os.makedirs(os.path.join(dir, sub_dir), exist_ok=True)\n",
    "        \n",
    "    for k, v in ret_dict.items():\n",
    "        if k in image_target_list:\n",
    "            for img_idx, each_img in tqdm(enumerate(v), total=len(v), desc=f\"Processing {k}\"):\n",
    "                object_id = ret_dict[\"object_id\"][img_idx]\n",
    "                object_id = object_id.replace(\"/\", \"_\")  # Replace slashes to avoid directory issues\n",
    "                \n",
    "                view_point_id = None\n",
    "                if k in [\"inputs\", \"control\"]:\n",
    "                    view_point_id = ret_dict[\"viewpoint_ids_cond\"][img_idx]\n",
    "                elif k in [\"reconstruction\", f\"samples_cfg_scale_{cfg_scale:.2f}\"]:\n",
    "                    view_point_id = ret_dict[\"viewpoint_ids_target\"][img_idx]\n",
    "                \n",
    "                # float to uint8 conversion\n",
    "                img = (each_img * 255).astype(\"uint8\")\n",
    "                if view_point_id is not None:\n",
    "                    img_name = f\"{object_id}_{view_point_id}.png\"\n",
    "                else:\n",
    "                    img_name = f\"{object_id}.png\"\n",
    "                Image.fromarray(img).save(os.path.join(dir, k, img_name))\n",
    "        \n",
    "\n",
    "def concat_writer(dir: str, ret_dict: dict, cfg_scale: float = 3.0):\n",
    "    # 기본 디렉토리 생성\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    image_target_list = [\"inputs\", \"reconstruction\", \"control\", f\"samples_cfg_scale_{cfg_scale:.2f}\"]\n",
    "    \n",
    "    # 개별 이미지 저장을 위한 하위 디렉토리 생성\n",
    "    for sub_dir in image_target_list:\n",
    "        os.makedirs(os.path.join(dir, sub_dir), exist_ok=True)\n",
    "    \n",
    "    # 기존 코드: 개별 이미지 저장\n",
    "    for k, v in ret_dict.items():\n",
    "        if k in image_target_list:\n",
    "            for img_idx, each_img in tqdm(enumerate(v), total=len(v), desc=f\"Processing {k}\"):\n",
    "                object_id = ret_dict[\"object_id\"][img_idx].replace(\"/\", \"_\")\n",
    "                \n",
    "                view_point_id = None\n",
    "                if k in [\"inputs\", \"control\"]:\n",
    "                    view_point_id = ret_dict[\"viewpoint_ids_cond\"][img_idx]\n",
    "                elif k in [\"reconstruction\", f\"samples_cfg_scale_{cfg_scale:.2f}\"]:\n",
    "                    view_point_id = ret_dict[\"viewpoint_ids_target\"][img_idx]\n",
    "                \n",
    "                # float에서 uint8로 변환\n",
    "                img = (each_img * 255).astype(\"uint8\")\n",
    "                if view_point_id is not None:\n",
    "                    img_name = f\"{object_id}_{view_point_id}.png\"\n",
    "                else:\n",
    "                    img_name = f\"{object_id}.png\"\n",
    "                Image.fromarray(img).save(os.path.join(dir, k, img_name))\n",
    "    \n",
    "    # 결합 이미지 생성 및 저장\n",
    "    combined_dir = os.path.join(dir, \"combined\")\n",
    "    os.makedirs(combined_dir, exist_ok=True)\n",
    "    \n",
    "    for img_idx in range(len(ret_dict[\"object_id\"])):\n",
    "        object_id = ret_dict[\"object_id\"][img_idx].replace(\"/\", \"_\")\n",
    "        view_point_id_target = ret_dict[\"viewpoint_ids_target\"][img_idx]\n",
    "        \n",
    "        # 이미지 가져오기\n",
    "        control_img = ret_dict[\"control\"][img_idx]\n",
    "        samples_img = ret_dict[f\"samples_cfg_scale_{cfg_scale:.2f}\"][img_idx]\n",
    "        reconstruction_img = ret_dict[\"reconstruction\"][img_idx]\n",
    "        \n",
    "        # uint8 형식으로 변환\n",
    "        control_img = (control_img * 255).astype(\"uint8\") if control_img.max() <= 1.0 else control_img.astype(\"uint8\")\n",
    "        samples_img = (samples_img * 255).astype(\"uint8\") if samples_img.max() <= 1.0 else samples_img.astype(\"uint8\")\n",
    "        reconstruction_img = (reconstruction_img * 255).astype(\"uint8\") if reconstruction_img.max() <= 1.0 else reconstruction_img.astype(\"uint8\")\n",
    "        \n",
    "        # 가로로 결합: [control, samples, reconstruction]\n",
    "        combined_img = np.concatenate([control_img, samples_img, reconstruction_img], axis=1)\n",
    "        \n",
    "        # 결합 이미지 저장\n",
    "        img_name = f\"{object_id}_{view_point_id_target}.png\"\n",
    "        Image.fromarray(combined_img).save(os.path.join(combined_dir, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b201323d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiModalControlNetV3: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.53 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    }
   ],
   "source": [
    "model = instantiate_from_config(target_cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdd6e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(weight_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9feaa1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verbose mode로 해서 path를 빼도록 만들기\n",
    "data = instantiate_from_config(target_cfg.data)\n",
    "target_cfg.data.params.validation.params.verbose = True\n",
    "target_cfg.data.params.validation.params.determin_view = True\n",
    "data.prepare_data()\n",
    "data.setup()\n",
    "val_dataloader = DataLoader(\n",
    "    data.datasets[\"validation\"], batch_size=data.batch_size,\n",
    "    num_workers=data.num_workers, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838295c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (64, 4, 32, 32), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:11<00:00,  1.42s/it]\n",
      " 12%|█▎        | 1/8 [01:29<10:29, 89.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (64, 4, 32, 32), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [01:11<00:00,  1.44s/it]\n",
      " 25%|██▌       | 2/8 [02:55<08:44, 87.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (64, 4, 32, 32), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "debug = False\n",
    "proc_result = {}\n",
    "cfg_scale = 3.0\n",
    "for idx, each_batch in tqdm(enumerate(val_dataloader), total=len(val_dataloader), leave=True):\n",
    "    \n",
    "    if debug:\n",
    "        if idx == 1:\n",
    "            break    \n",
    "    \n",
    "    ret = model.log_val_images(\n",
    "        each_batch,\n",
    "        N=len(each_batch[\"image_target\"]),\n",
    "        unconditional_guidance_scale=cfg_scale,\n",
    "        unconditional_guidance_label=[\"\"],\n",
    "        use_ema_scope=False,\n",
    "        inpaint=False,\n",
    "        plot_progressive_rows=False,\n",
    "        plot_diffusion_rows=False\n",
    "    )\n",
    "    \n",
    "    if idx == 0:\n",
    "        proc_result = {}\n",
    "        for k in ret.keys():\n",
    "            \n",
    "            if k == \"viewpoint_ids\":\n",
    "                proc_result[f\"{k}_cond\"] = []\n",
    "                proc_result[f\"{k}_target\"] = []   \n",
    "            \n",
    "            else:\n",
    "                proc_result[k] = []\n",
    "    \n",
    "    for k, v in ret.items():\n",
    "        if k in [\"inputs\", \"reconstruction\", \"control\", f\"samples_cfg_scale_{cfg_scale:.2f}\"]:\n",
    "            _v = v.cpu()\n",
    "            _v = convert_to_npy(split_by_unbind(_v))\n",
    "            proc_result[k].extend(_v)\n",
    "        if \"viewpoint_ids\" in k:\n",
    "            proc_result[f\"{k}_cond\"].extend(v[\"cond\"])\n",
    "            proc_result[f\"{k}_target\"].extend(v[\"target\"])\n",
    "        if k in [\"object_id\", \"txt\"]:\n",
    "            proc_result[k].extend(v)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10311a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer part\n",
    "exp_name = os.path.basename(config_path).split('.')[0]  \n",
    "total_writer(\n",
    "    dir=f\"results/{exp_name}\",\n",
    "    ret_dict=proc_result,\n",
    ")\n",
    "concat_writer(\n",
    "    dir=f\"results/{exp_name}\",\n",
    "    ret_dict=proc_result,\n",
    "    cfg_scale=cfg_scale\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
